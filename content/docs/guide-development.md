# MMODA workflow development Guide

The MMODA platform provides access to the Astronomical Open Research Data Analysis Serfives (Astro-ORDAS). Good fraction of these services follow a simple scheme: they are  
* accessing publicly available external astronomical data archives to fetch data relevant to specific source or source catalog and
* transform the fetched data using a workflow based on a Python notebook, to drive a data product
* display a preview of the data product on the MMODA frontend and/or return the data product to the user

The users of MMODA are encouraged to become its developers and add new AstroORDAS. This help page provides a step-by step instructions on how to add new services to MMODA.

Workflows are all things that can be computed, broadly speaking. For reproducibility, we want our workflows to be repeatable: producing the same output every time they are computed. This looks easy enough in first approximation, but might be harder to achieve than it seems when the workflow relies on external data and compute resources  and has to yield an "up-and-running" ORDAS in an ever-evolving compute environment. This help page is also aimed at helping the developers in improving the reproducibility and reusability of their workflows converted to services.

## Simple ODA Jupyter Notebook to a workflow

### 1) Write a working repeatable parameterized workflow

Suppose you have a [**jupyter notebook**](https://renkulab.io/projects/astronomy/mmoda/fermi/files/blob/Lightcurve.ipynb) that derives some useful information (a lightcurve in the GeV gamma-ray band) on an astronomical source (for example, a blazar [Mrk 421](http://simbad.u-strasbg.fr/simbad/sim-id?Ident=Mrk++421)) from data found in an astronomical data archive (in our example, it will be [Fermi LAT data archive](https://fermi.gsfc.nasa.gov/ssc/data/access/)). 

The first essential step in promoting the notebook to an ORDAS is to make the workflow of the notebook **reusable** by parameterizing it. For example, it is initeresting to enable generation of similar data products for different sources, by simply giving the source name or coordinates as **input parameters** to the workflow). It is also useful to explicitly tag the resulting data product (the lightcurve in our example) as the **output**, to make clear which of the numerous entities generated by the notebook is the final result. It is also possibly to convert non-parametrized but strickly repeatable notebooks to services (for example, to assure reproducibility of a result published in a research publication), but this is less interesting since they always produce the same output data. 

#### How to designate input parameters and output cells of the notebook 

In MMODA we use the approach of [papermill](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#designate-parameters-for-a-cell)) to **tag* the notebook cells that contain input parameters and the outputs. In your notebook, you may create two dedicated cells with the "parameters" tag. In the Jupyter Lab environment this can be done by clicking on the cogwheel sign on the right top, red arrow in the image below, and adding new tag as pointed by the second red arrow:
![image](https://github.com/oda-hub/hugo-odahub/blob/master/content/docs/tmp1.png)

#### How to define input parameters in the dedicated parameters cell 

The variables defined in the dedicated "parameters" cell, will be the input parameters of the workflow. They will be visualized in the frontend of the service and it will be possible to provide these parameters via the service Application Programming Interface (API). For example, in the image of the parameters cell in our example (see above), the
  * the names of the declared variables will be used as parameter names in the MMODA service (except the **default** parameters, see below). For example, the `Source_region_radius` variable will be visible in the frontend as a query parameter with the same name. It will appear with a default value assigned to it (`2.` in the example notebook). 
  * if not annotated, the types of the inputs parameters are determined based on the parameter default value (would be `float` for the `Source_region_radius` parameter).
  * otherwise, it is possible to customize the parameter by adding annotation the input parameter with an MMODA [ontology](https://odahub.io/docs/guide-ontology) item as a comment (after the hash sign, `#http://odahub.io/ontology#AngleDegrees` in the reference example of the `Source_region_radius` parameter. This may be useful for checking the validity of the user inputs. For example, the sky angle in degrees (defined by the `#http://odahub.io/ontology#AngleDegrees`) should be a float number and can take values between 0 and 360. 

#### Default parameters

Several **default** common parameters are always set by the MMODA frontend. These include:

  | Type annotation | Parameter default name |
  | ---------------- | -------------- |
  | http://odahub.io/ontology#PointOfInterestRA | RA |
  | http://odahub.io/ontology#PointOfInterestDEC | DEC |
  | http://odahub.io/ontology#StartTime | T1 |
  | http://odahub.io/ontology#EndTime | T2 |
  | http://odahub.io/ontology#AstrophysicalObject | src_name |
  
If the notebook contains parameters anotated with these types, their names will be automatically converted by the dispatcher plugin to the default ones. If some of them are ommited, they will be added to the list of workflow parameters automatically. The default parameters are common to all workflows in the MMODA ecosystem. They appear at the top of the MMODA frontend as shown below:

![image](https://github.com/oda-hub/hugo-odahub/blob/master/content/docs/tmp2.png)

Note that both target (Point of Interest) **source name** and target **source coordinates** are passed to the workflow, and in principle there is no guarantee the coordinates are that of the source. We leave is up to the workflow developer to reconcile these parameters. Please explain the logic in the associated help page of the service.

#### Adding annotations the entire notebook

Annotations can apply to parameters or entire notebook. In both cases they are kept in the notebook cell tagged `parameters`.
For example:

```
# oda:version "v0.1.1"
# oda:reference "https://doi.org/10.1051/0004-6361/202037850"

source_name = "Crab" # oda:AstrophysicalObject
reference_energy = 20 # oda:keV
```   
 #### How to annotate the notebook outputs

A cell tagged "outputs" defines the data product(s) that will be provided by the service:

![image](https://github.com/oda-hub/hugo-odahub/blob/master/content/docs/tmp3.png)


The outputs may be strings, floats, lists, numpy arrays, astropy tables etc. They may be also strings which contain filenames for valid files. If they do, the whole file will be considered as the output.  Similar to the "parameters" cell, the "outputs" cell should contain the definitions of the output variables followed by equality that assigns values to them and a comment that defines their type (for example, the variable `lightcurve_astropy_table` in the example shown above takes the value `lightcurve` which is an astropy table. the comment field `# http://odahub.io/ontology#ODAAstropyTable` specifies this in terms of the MMODA ontology. If you want to give more detailed description of the notebook input and output, use `terms` from the pre-defined ontology described  [here]([docs/guide-ontology.](https://odahub.io/docs/guide-ontology)).

 ### 2) Make the notebook available for deployment on [MMODA](https://www.astro.unige.ch/mmoda/) via [renkulab.io](https://renkulab.io/)

The parameterized workflow formulated as a Python notebook can be converted into a service provided by [MMODA](https://www.astro.unige.ch/mmoda/)  by a bot that scans a specific location `astronomy/mmoda` in the project directory on the  [renkulab.io](https://renkulab.io/) collaborative platform. Creating a new project in this directory will make it visible for the bot. In our example of Fermi/LAT lightcurve workflow, it is in the [fermi](https://renkulab.io/projects/astronomy/mmoda/fermi) subdirectory of `astronomy/mmoda`.

First you need to make sure your notebook runs in a cloud environment. It needs to be repeatable - i.e. you can run it many times. If it depends on external services - try to make sure the requests are also repeatable - you might need to specify sufficient details. If the notebook does not produce the exactly
the same result every time - it's unfortunate, but do not worry too much, it might still be reproducible (see motivation on [the difference between reproducibility and repeatability](https://github.com/volodymyrss/reproducibility-motivation/))

* write your notebook, and make sure it runs from top to bottom
* make a requirements.txt will the modules you need for this notebook

You can use mock [notebooks](https://renkulab.io/gitlab/astronomy/mmoda/mmoda-nb2workflow-example/-/tree/master/notebooks) as examples.





### Publish your workflow as a test service
* publish the workflow to RenkuLab in the dedicated group: https://renkulab.io/gitlab/astronomy/mmoda/
* add a "live-workflow" topic.

![](../live-workflow-tag-set.png)
![](../live-workflow-tag.png)


* once some bots do their job, the workflow will be automatically installed in [MMODA](https://www.astro.unige.ch/mmoda) (by default, on a staging instance), and you will recieve an email!
####  Try to access your new service

* Assuming `lightcurve-example` from above was used, and the notebook name was `random`, you can run this:

```bash
$ oda-api -u https://dispatcher-staging.odahub.io get -i lightcurve-example -p random -a n_bins=5
```

TODO: workflow version, plot here and in renku create



### (optional) Try a test service

* install nb2workflow tooling `pip install 'nb2workflow[cwl,service,rdf,mmoda]>=1.3.30' --upgrade`. Note that his command should be the only one you need to install the necessary dependencies for the workflow engine. You may of course also need some domain-specific packages .
* inspect the notebook `nbinspect my-notebook.ipynb`
* try to run the notebook `nbrun my-notebook.ipynb`
  * it will use all default parameters 
  * you can specify parameters as `nbrun --inp-nbins=10 my-notebook.ipynb`, if `nbins` happens to be one of the parameters.
 try to start the service `nb2service my-notebook.ipynb`

{{< notice note >}}
if you experience issues testing the service due to some "import error" or other strange messages try containerized service (note that it will not work in Renku):

* `nb2deploy $PWD test --local`
* then, look onto http://0.0.0.0:8000 for some metadata about the service
* try to run some simple queries in http://0.0.0.0:8000/apidocs/
{{< /notice >}}

{{< notice note >}}
If you still experience issues with local environment, try to develop the workflow directly in [renkulab]() - note that some commands, `like nb2deploy`, will not work in this case.
{{< /notice >}}

### Developing service in Renku


https://renkulab.io/

TODO: explain how to run server



### (optional) Add some verification test cases

To make sure your service does not break with future updates, it's useful to express some assumptions about the service outputs in some reference cases.
They will be tested automatically every time new workflow version is installed.

we will explain later how to do this.
